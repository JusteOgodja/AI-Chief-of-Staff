# Copy to .env. Par défaut le projet utilise Ollama (gratuit, local).
# LLM: ollama (défaut) | none (heuristique) | openai
LLM_PROVIDER=ollama
# Ollama (installer depuis https://ollama.ai puis: ollama run llama3.2)
OLLAMA_MODEL=llama3.2
OLLAMA_BASE_URL=http://localhost:11434
# Optionnel, si LLM_PROVIDER=openai:
# OPENAI_API_KEY=sk-...
# OPENAI_MODEL=gpt-4o-mini
